{"total_rows":14,"offset":0,"rows":[
{"id":"0d2b90ce254087e35a14caa2c2078aa63594c31a","key":"0d2b90ce254087e35a14caa2c2078aa63594c31a","value":1,"doc":{"_id":"0d2b90ce254087e35a14caa2c2078aa63594c31a","_rev":"6-77d618d27e0eae256c0982a7f44a42ed","name":"spark-cloudant connector","full_name":"Spark SQL Cloudant External Datasource","description":"Cloudant integration with Spark as Spark SQL external datasource. Most of the implementation can be re-used by other JsonStore, e.g. Riak. ","body":"Skip to content Sign up Sign in This repository * Explore * Features * Enterprise * Pricing * Watch 95 * Star 7 * Fork 7CLOUDANT-LABS / SPARK-CLOUDANT * Code * Issues * Pull requests * Pulse * GraphsHTTPS CLONE URLSUBVERSION CHECKOUT URLYou can clone with HTTPS or Subversion . Download ZIP Cloudant integration with Spark as Spark SQL external datasource * 24 commits * 3 branches * 11 releases * 3 contributors 1. Scala 84.9% 2. Python 15.1%Scala Python Branch: master Switch branches/tags * Branches * Tags55905_long_type_cast master snowch-patch-1 Nothing to show v1.4.1.5 v1.4.1.4 v1.4.1.3 v1.4.1.2 v1.4.1.1 v1.4.1.0 v1.3.1.2 v1.3.1.1 v1.0 v0.1 1.4.0.0 Nothing to show spark-cloudant / Latest commit 6dbd897 Nov 2, 2015 HolgerKache Add release v1.4.1.4 to README Permalink Failed to load latest commit information. CLAs initial commit Mar 19, 2015 cloudant-spark-sql Merge pull request #7 from yanglei99/master Oct 30, 2015 python bulk save Sep 8, 2015 spark-test upgrade to Spark 1.5.1 Oct 13, 2015 LICENSE initial commit Mar 19, 2015 README.md Add release v1.4.1.4 to README Nov 2, 2015 README_build.md revise build content Aug 20, 2015 README_submit.md define cloudant configuration in dataframe option Aug 20, 2015README.MDSPARK SQL CLOUDANT EXTERNAL DATASOURCECloudant integration with Spark as Spark SQL external datasource. Most of theimplementation can be re-used by other JsonStore, e.g. Riak.CONTENTS:RELATIONPROVIDER IMPLEMENTATIONSAll implementions are under hereCLOUDANTRelation Provider Name Table Option Scan Type Column Pruning Predicates Push Down Parallel Loading Insertable Source Code Location com.cloudant.spark.DefaultSource database or path, index PrunedFilteredScan Yes _id or first predicate Yes, except with index Yes DefaultSource.scala com.cloudant.spark.CloudantRP database TableScan No No No No CloudantDatasource.scala com.cloudant.spark.CloudantPrunedFilteredRP database PrunedFilteredScan Yes _id or first predicate No No CloudantPrunedFilteredDatasource.scala com.cloudant.spark.CloudantPartitionedPrunedFilteredRP database, index PrunedFilteredScan Yes _id or first predicate Yes, except with index No CloudantPartitionedPrunedFilteredDatasource.scalaRIAKRelation Provider Name Table Option Scan Type Column Pruning Predicates Push Down Parallel Loading Insertable Source Code Location com.cloudant.spark.CloudantPartitionedPrunedFilteredRP path PrunedFilteredScan Yes first predicate Yes No RiakPartitionedPrunedFilteredDatasource.scalaBINARY DOWNLOAD:Spark Version Release # Binary Location 1.3.0 v0.1 Location 1.3.1 v1.3.1.2 Location 1.4.0 v1.4.0.0 Location 1.4.1 v1.4.1.3 Location 1.4.1 v1.4.1.4 Location 1.5.1 v1.5.1.0 LocationBUILD FROM SOURCE:InstructionsSAMPLE APPLICATIONUSING SQL IN PYTHONpython codeconf = SparkConf().setAppName(\"Cloudant Spark SQL External Datasource in Python\")# define cloudant related configurationconf.set(\"cloudant.host\",\"ACCOUNT.cloudant.com\")conf.set(\"cloudant.username\", \"USERNAME\")conf.set(\"cloudant.password\",\"PASSWORD\")# create Spark context and SQL contextsc = SparkContext(conf=conf)sqlContext = SQLContext(sc)# create temp tablesqlContext.sql(\"CREATE TEMPORARY TABLE airportTable USING com.cloudant.spark.CloudantRP OPTIONS ( database 'airportcodemapping')\")# create Schema RDDdata = sqlContext.sql(\"SELECT airportCode, airportName FROM airportTable WHERE airportCode >= 'CAA' ORDER BY airportCode\")# print schemadata.printSchema()# print datafor code in data.collect():    print code.airportCodeUSING SQL IN SCALAScala codeval conf = new SparkConf().setAppName(\"Cloudant Spark SQL External Datasource in Scala\")// define cloudant related configuration    conf.set(\"cloudant.host\",\"ACCOUNT.cloudant.com\")conf.set(\"cloudant.username\", \"USERNAME\")conf.set(\"cloudant.password\",\"PASSWORD\")// create Spark context and SQL contextval sc = new SparkContext(conf)val sqlContext = new SQLContext(sc)import sqlContext._// Create a temp table sqlContext.sql(\"CREATE TEMPORARY TABLE airportTable USING com.cloudant.spark.CloudantRP OPTIONS ( database 'airportcodemapping'\")// create Schema RDDval data = sqlContext.sql(\"SELECT airportCode, airportName FROM airportTable WHERE airportCode >= 'CAA' ORDER BY airportCode\"\")// print schemadata.printSchema()// print datadata.map(t => \"airportCode: \" + t(0) +\"airportName: \" + t(1)).collect().foreach(println) USING DATAFRAME IN PYTHONpython code .conf = SparkConf().setAppName(\"Cloudant Spark SQL External Datasource in Python\")# define coudant related configurationconf.set(\"cloudant.host\",\"ACCOUNT.cloudant.com\")conf.set(\"cloudant.username\", \"USERNAME\")conf.set(\"cloudant.password\",\"PASSWORD\")sc = SparkContext(conf=conf)sqlContext = SQLContext(sc)df = sqlContext.load(\"airportcodemapping\", \"com.cloudant.spark\")df.printSchema()df.filter(df.airportCode >= 'CAA').select(\"airportCode\",'airportName').save(\"airportcodemapping_df\", \"com.cloudant.spark\")      Sample code on using DataFrame option to define cloudant configurationUSING DATAFRAME IN SCALAScala codeval conf = new SparkConf().setAppName(\"Cloudant Spark SQL External Datasource in Scala\")// define cloudant related configuration    conf.set(\"cloudant.host\",\"ACCOUNT.cloudant.com\")conf.set(\"cloudant.username\", \"USERNAME\")conf.set(\"cloudant.password\",\"PASSWORD\")// create Spark context and SQL contextval sc = new SparkContext(conf)val sqlContext = new SQLContext(sc)import sqlContext._ val df = sqlContext.read.format(\"com.cloudant.spark\").load(\"airportcodemapping\") df.printSchema() df.filter(df(\"airportCode\") >= \"CAA\").select(\"airportCode\",\"airportName\").show() df.filter(df(\"airportCode\") >= \"CAA\").select(\"airportCode\",\"airportName\").write.format(\"com.cloudant.spark\").save(\"airportcodemapping_df\")Sample code on using DataFrame option to define cloudant configurationNOTE:In the above table creation, you can replace \"USINGcom.cloudant.spark.CloudantRP\" with other RelationProvider implementationsJOB SUBMISSIONDetailsFOR PYTHONspark-submit  --master local[4] --jars <path to cloudant-spark.jar>  <path to python script> FOR SCALAspark-submit --class \"<your class>\" --master local[4] --jars <path to cloudant-spark.jar> <path to your app jar>CONFIGURATION OVERVIEWCONFIGURATION ON SPARKCONFConfiguration can also be passed on DataFrame using option, which overrides whatis defined in SparkConfName Default Meaning cloudant.host cloudant host url cloudant.username cloudant userid cloudant.password cloudant password riak.host riak ip address riak.port riak port jsonstore.rdd.partitions 5 the number of partitions intent used to drive JsonStoreRDD loading query resultin parallel. The actual number is calculated based on total rows returned andsatisfying maxInPartition and minInPartition jsonstore.rdd.maxInPartition -1 the max rows in a partition. -1 means unlimited jsonstore.rdd.minInPartition 10 the min rows in a partition. jsonstore.rdd.requestTimeout 100000 the request timeout in milli-second jsonstore.rdd.concurrentSave -1 the parallel saving size. -1 means unlimited jsonstore.rdd.bulkSize 1 the bulk save size.Default values are defined in hereCONFIGURATION ON SPARK SQL TEMP TABLEConfiguration can also be passed on DataFrame using option.Name Default Meaning database cloudant database name index cloudant search index w/o the database name.only used for load. path riak: search index name; cloudant: as database name if database does notpresentKNOWN LIMITATIONS AND IMPROVEMENT AREAS * Chunked response is not supported. For parallel partitioned loading, issue   can be workarouded by setting jsonstore.rdd.maxInPartition. The following is   the exception when query result is over limit. HttpClientConnection:   Aggregated response entity greater than configured limit of 1048576   bytes,closing connection java.lang.RuntimeException: sendReceive doesn't   support chunked response       * TableScan in cases hits IndexOutOfRangeException       * Schema is calculated on the first document w/o any predicate push down. Need   a better approach       * Cloudant search index query does not support \"paging\" through skip and limit.       * Need to improve how number of partitions is determined for parallel loading       * Status * API * Training * Shop * Blog * About * Pricing * © 2015 GitHub , Inc. * Terms * Privacy * Security * Contact * HelpSomething went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session.","url":"https://github.com/cloudant-labs/spark-cloudant/","created_at":"2015-11-11 01:52:04 +00:00","updated_at":"2015-11-11 01:52:04 +00:00","imageurl":"https://avatars0.githubusercontent.com/u/1815157?v=3&s=400","status":"Live","languages":["Python","SQL"],"technologies":["Cloudant","Spark"],"topic":["NoSQL","Analytics"],"featured":"false","demourl":"","githuburl":"https://github.com/cloudant-labs/spark-cloudant/","videourl":"","documentationurl":"","author":"","otherurl":"","level":"Intermediate","type":"Article","namespace":["Cloud Data Services"],"related_ids":[]}},
{"id":"16f34b4dc9f26628eb1a021c338d46fbb2da036a","key":"16f34b4dc9f26628eb1a021c338d46fbb2da036a","value":1,"doc":{"_id":"16f34b4dc9f26628eb1a021c338d46fbb2da036a","_rev":"4-e5f55891156173dc3ef146bb19dd6784","name":"java-cloudant library","full_name":"cloudant/java-cloudant","description":"The official Cloudant library for Java.","body":"Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository * Watch 102 * Star 27 * Fork 25CLOUDANT / JAVA-CLOUDANTCode Issues 17 Pull requests 0 Pulse Graphs A Java client for Cloudant * 640 commits * 16 branches * 19 releases * 22 contributors 1. Java 96.4% 2. HTML 3.0% 3. JavaScript 0.6%Java HTML JavaScript New file Find file HTTPS Choose a clone URL HTTPS (recommended) Clone with Git or checkout with SVN using the repository's web address. HTTPS Learn more about clone URLs Download ZIP Branch: master Switch branches/tags * Branches * Tags119-db-intf 119-db-proxy-cache 147-sentinel 175-seqId-json 50101-cache-db 60008-http-429-backoff 64095-smaller-ua feature-119-cache feature-119 feature-http-updates maintenance-1.2 master okhttp3 priorCloudantWrappers proxy-auth v1.0.2 Nothing to show 2.4.2 2.4.2-rc.1 2.4.1 2.4.1-rc.1 2.4.0 2.3.0 2.2.0 2.1.0 2.0.0 1.2.3 1.2.2 1.2.1 1.2.0 1.1.2 1.1.1 1.1.0 1.0.1 1.0.0 1.0.0-beta1 Nothing to show New pull request Latest commit cae7171 Apr 27, 2016 ricellis Merge pull request #246 from cloudant/64095-smaller-ua …Reduced the length of the User-Agent stringPermalink Failed to load latest commit information. .github Fix typo Feb 22, 2016 .idea Latest IDEA settings Aug 13, 2015 cloudant-client Reduced the length of the User-Agent string Apr 21, 2016 cloudant-http Changed to use JVM default chunk size Mar 24, 2016 gradle/ wrapper Make Test Cases Configurable May 26, 2015 guide updated maven link for javadocs Oct 27, 2014 .gitignore Added new test category classes Jul 24, 2015 .travis.yml Added jdk8 to travis builds Dec 16, 2015 CHANGES.md Reduced the length of the User-Agent string Apr 21, 2016 CONTRIBUTING.md Split http and client into subprojects Mar 7, 2016 LICENSE update readme & license Mar 16, 2014 README.md Prepare for 2.4.2 release Apr 7, 2016 build.gradle Updated version to 2.4.3-SNAPSHOT Apr 7, 2016 gradlew Make Test Cases Configurable May 26, 2015 gradlew.bat Make Test Cases Configurable May 26, 2015 settings.gradle Split http and client into subprojects Mar 7, 2016README.MDCLOUDANT JAVA CLIENTThis is the official Cloudant library for Java. * Installation and Usage * Getting Started * API Reference (javadoc) * Related Documentation * Development * Contributing    * Test Suite    * Using in Other Projects    * License    * Issues      INSTALLATION AND USAGEGradle:dependencies {    compile group: 'com.cloudant', name: 'cloudant-client', version: '2.4.2'}Gradle with optional okhttp-urlconnection dependency :dependencies {    compile group: 'com.cloudant', name: 'cloudant-client', version: '2.4.2'    compile group: 'com.squareup.okhttp', name: 'okhttp-urlconnection', version: '2.7.5'}Maven:<dependency>  <groupId>com.cloudant</groupId>  <artifactId>cloudant-client</artifactId>  <version>2.4.2</version></dependency>Maven with optional okhttp-urlconnection dependency :<dependency>  <groupId>com.cloudant</groupId>  <artifactId>cloudant-client</artifactId>  <version>2.4.2</version></dependency><dependency>  <groupId>com.squareup.okhttp</groupId>  <artifactId>okhttp-urlconnection</artifactId>  <version>2.7.5</version></dependency>Optional OkHttp dependencyHTTP requests to the database are made using java.net.HttpURLConnection . Adding the optional dependency for the okhttp-urlconnection changes the HttpURLConnection from the default JVM implementation to the OkHttp implementation. Note that touse OkHttp requires a minimum of Java 1.7.The main use case that is supported by this optional dependency is configurationof connection pools on a per CloudantClient basis ( see the javadoc for ClientBuilder.maxConnections). If the OkHttp dependency is available atruntime it will be used automatically. Not using OkHttp will result in a smallerapplication size.GETTING STARTEDThis section contains a simple example of creating a com.cloudant.client.api.CloudantClient instance and interacting with Cloudant.For further examples and more advanced use cases see the javadoc for the version you are using. The source code for the tests in this githubproject also contains many examples of API usage.// Create a new CloudantClient instance for account endpoint example.cloudant.comCloudantClient client =ClientBuilder.account(\"example\")                                     .username(\"exampleUser\")                                     .password(\"examplePassword\")                                     .build();// Note: for Cloudant Local or Apache CouchDB use:// ClientBuilder.url(new URL(\"yourCloudantLocalAddress.example\"))//              .username(\"exampleUser\")//              .password(\"examplePassword\")//              .build();// Show the server versionSystem.out.println(\"Server Version: \"+ client.serverVersion());// Get a List of all the databases this Cloudant accountList<String> databases = client.getAllDbs();System.out.println(\"All my databases : \");for ( String db : databases ) {    System.out.println(db);}// Working with data// Delete a database we created previously.client.deleteDB(\"example_db\");// Create a new database.client.createDB(\"example_db\");// Get a Database instance to interact with, but don't create it if it doesn't already existDatabase db = client.database(\"example_db\", false);// A Java type that can be serialized to JSONpublicclassExampleDocument {  privateString _id =\"example_id\";  privateString _rev =null;  privateboolean isExample;  publicExampleDocument(booleanisExample) {    this.isExample = isExample;  }  publicStringtoString() {    return\"{ id: \"+ _id +\",\\nrev: \"+ _rev +\",\\nisExample: \"+ isExample +\"\\n}\";  }}// Create an ExampleDocument and save it in the databasedb.save(newExampleDocument(true));System.out.println(\"You have inserted the document\");// Get an ExampleDocument out of the database and deserialize the JSON into a Java typeExampleDocument doc = db.find(ExampleDocument.class,\"example_id\");System.out.println(doc);Output:Server version = 1.0.2All my databases: example_db, stuff, scoresYou have inserted the document.{ id: example_id,  rev: 1-6e4cb465d49c0368ac3946506d26335d,  isExample: true}There is significantly more documentation, including additional code samples andexplanations, in the javadoc . The first page you land on when following the javadoc link includes a tableof contents with further links to help guide you to the documentation you need.To find the additional information be sure to scroll down past theauto-generated summary tables and do not overlook the package overviews.RELATED DOCUMENTATION * API reference (javadoc) * Cloudant docs * Cloudant for developersDEVELOPMENTFor information about contributing, building, and running tests see the CONTRIBUTING.md .USING IN OTHER PROJECTSThe preferred approach for using java-cloudant in other projects is to use theGradle or Maven dependency as described above.LICENSECopyright 2014-2015 Cloudant, an IBM company.Licensed under the apache license, version 2.0 (the \"license\"); you may not usethis file except in compliance with the license. you may obtain a copy of thelicense athttp://www.apache.org/licenses/LICENSE-2.0.htmlUnless required by applicable law or agreed to in writing, software distributedunder the license is distributed on an \"as is\" basis, without warranties orconditions of any kind, either express or implied. See the license for thespecific language governing permissions and limitations under the license.ISSUESIf you are a Cloudant customer please contact Cloudant support for help with anyissues.It is also possible to open issues here in github . * Status * API * Training * Shop * Blog * About * © 2016 GitHub , Inc. * Terms * Privacy * Security * Contact * HelpSomething went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session.","url":"https://github.com/cloudant/java-cloudant","created_at":"2016-04-29 16:45:48 +00:00","updated_at":"","imageurl":"","status":"Live","languages":["Java","HTTP API"],"technologies":["Cloudant"],"topic":["NoSQL"],"featured":"false","demourl":"","githuburl":"https://github.com/cloudant/java-cloudant","videourl":"","documentationurl":"","author":"","otherurl":"","level":"Intermediate","type":"Tutorial","namespace":["Cloud Data Services"],"related_ids":[]}},
{"id":"1b1ea98ed32e778a102caa3f40ba24aaa58ef9b5","key":"1b1ea98ed32e778a102caa3f40ba24aaa58ef9b5","value":1,"doc":{"_id":"1b1ea98ed32e778a102caa3f40ba24aaa58ef9b5","_rev":"4-5e1448e686d9e88e223da9d512e3b043","name":"meteor-couchdb library","full_name":"cloudant/meteor-couchdb","description":"Meteor database driver for CouchDB and Cloudant","body":"The couchdb package is a Meteor package available onAtmosphere. The package is a full stack databasedriver that provides functionality to work with Apache CouchDB in Meteor.* an efficient Livequery implementation providing real-timeupdates from the database by consuming the CouchDB _changes feed* Distributed Data Protocol (DDP) RPC end-points for updating the data from clients connected over the wire* Serialization and deserialization of updates to the DDP formatThis Readme covers the followingAdd this package to your Meteor app:meteor add cloudant:couchdbSince Apache CouchDB is not shipped with Meteor or this package, you need to have a running CouchDB/Cloudant server and a url to connect to it.Note: The JSON query syntax used is 'Cloudant Query', initially developed by Cloudant and contributed back to Apache CouchDB version 2.0. Pre-built binaries of Apache CouchDB 2.0 are not yet available, so the easiest way to use this module is with Cloudant DBaas or LocalTo configure the Apache CouchDB/Cloudant server connection information, pass its url as the COUCHDB_URLenvironment variable to the Meteor server process.$export COUCHDB_URL=https://username:password@username.cloudant.comJust like Mongo.Collection, you will work with CouchDB.Database for CouchDB data.You can instantiate a CouchDB.Database on both client and on the server.var Tasks = new CouchDB.Database(\"tasks\");The database wraps the Cloudant Query commands.  If a callback is passed then the commands execute asynchronously.  If no callback is passed, on the server, the call is executed synchronously (technically this uses fibers and only appears to be synchronous, so it does not block the event-loop).  If you're on the client and don't pass a callback, the call executes asynchronously and you won't be notified of the result.One can publish a cursor on the server and the client subscribe to it.if (Meteor.isServer) {// This code only runs on the serverMeteor.publish(\"tasks\", function () {return Tasks.find();if (Meteor.isClient) {// This code only runs on the clientMeteor.subscribe(\"tasks\");This way data will be automatically synchronized to all subscribed clients.Latency compensation works with all supported commands used either at the client or client's simulations.Once you remove the insecure package, you can allow/deny database modifications from the client//make sure no extra properties besides postContent are included in the insert operationTasks.allow({insert: function (userId, doc) {return _.without(_.keys(doc), 'postContent').length === 0;Apache CouchDB stores data in Databases. To get started, declare a database with new CouchDB.Database.new CouchDB.Database(name, [options])Constructor for a DatabaseArgumentsname StringThe name of the database. If null, creates an unmanaged (unsynchronized) local database.Optionsconnection ObjectThe server connection that will manage this database. Uses the default connection if not specified. Pass the return value of calling   DDP.connect to specify a different server. Pass null to specify no connection. Unmanaged (name is null) databases cannot specify a connection.idGeneration StringThe method of generating the _id fields of new documents in this database. Possible values:'STRING': random stringsThe default id generation technique is 'STRING'.Calling this function sets up a database (a storage space for records, or \"documents\") that can be used to store a particular type of information that matters to your application. Each document is a JSON object. It includes an _id property whose value is unique in the database, which Meteor will set when you first create the document.// common code on client and server declares a DDP-managed couchdb// database.Chatrooms = new CouchDB.Database(\"chatrooms\");Messages = new CouchDB.Database(\"messages\");The function returns an object with methods to insert documents in the database, update their properties, and remove them, and to find the documents in the database that match arbitrary criteria. The way these methods work is compatible with the popular CouchDB JSON Query syntax. The same database API works on both the client and the server (see below).// return array of my messagesvar myMessages = Messages.find({userId: Session.get('myUserId')}).fetch();// create a new messagevar id = Messages.insert({text: \"Hello, world!\"});// mark my first message as \"important\"Messages.update({_id: id, text: 'Hello, world!', important: true });If you pass a name when you create the database, then you are declaring a persistent database — one that is stored on the server and seen by all users. Client code and server code can both access the same database using the same API.Specifically, when you pass a name, here's what happens:On the server (if you do not specify a connection), a database with that name is created on the backend CouchDB server. When you call methods on that database on the server, they translate directly into normal CouchDB operations (after checking that they match your access control rules).On the client (and on the server if you specify a connection), Meteor's Minimongo is reused i.e. Minimongo instance is created. Queries (find) on these databases are served directly out of this cache, without talking to the server.When you write to the database on the client (insert, update, remove), the command is executed locally immediately, and, simultaneously, it's sent to the server and executed there too. This happens via stubs, because writes are implemented as methods.When, on the server, you write to a database which has a specified connection to another server, it sends the corresponding method to the other server and receives the changed values back from it over DDP. Unlike on the client, it does not execute the write locally first.If you pass null as the name, then you're creating a local database. It's not synchronized anywhere; it's just a local scratchpad that supports find, insert, update, and remove operations. (On both the client and the server, this scratchpad is implemented using Minimongo.)Find the documents in a database that match the selector.Argumentsselector : Selector specifier,  or StringA query describing the documents to find.optionssort Sort specifierSort orderskip NumberNumber of results to skip at the beginninglimit NumberMaximum number of results to returnfields :  Field specifierfields to returnfind returns a cursor. It does not immediately access the database or return documents. Cursors provide fetch to return all matching documents, map and forEach to iterate over all matching documents, and observe and observeChanges to register callbacks when the set of matching documents changes.Cursors are not query snapshots. Cursors are a reactive data source. Any change to the database that changes the documents in a cursor will trigger a recomputation.Finds the first document that matches the selector, as ordered by sort and skip options.Argumentsselector : Selector specifier,  or StringA query describing the documents to find.optionssort Sort SpecifierSort orderskip NumberNumber of results to skip at the beginninglimit NumberMaximum number of results to returnfields : Field specifierfields to returnInsert a document in the database. Returns its unique _id.Argumentsdoc ObjectThe document to insert. May not yet have an _id attribute, in which case Meteor will generate one for you.callback FunctionOptional. If present, called with an error object as the first argument and, if no error, the _id as the second.Add a document to the database. A document is just an object, and its fields can contain any combination of compatible datatypes (arrays, objects, numbers, strings, null, true, and false).insert will generate a unique ID for the object you pass, insert it in the database, and return the ID.Replace a document in the database. Returns 1 if document updated, 0 if not.Argumentsdoc JSON document with _id fieldthe _id field in this doc specifies which document in the database is to be replaced by this document's content.optionsupsert BooleanTrue to insert a document if no matching document is found.callback FunctionOptional. If present, called with an error object as the first argument and, if no error, returns 1 as the second.Replace a document that matches the _id field. This is done on the Apache CouchDB Server via a updateHandler ignoring the _rev field (Hence behaviour is same as last-writer-wins)Returns 1 from the update call if successful and you don't pass a callback.You can use update to perform a upsert by setting the upsert option to true. You can also use the upsert method to perform an upsert that returns the _id of the document that was inserted (if there was one)Replace a document in the database, or insert one if no matching document were found. Returns an object with keys numberAffected (1 if successful, otherwise 0) and insertedId (the unique _id of the document that was inserted, if any).Argumentsdoc JSON document with _id fieldthe _id field in this doc specifies which document in the database is to be replaced by this document's content if exists. If doesnt exist document is insertedcallback FunctionOptional. If present, called with an error object as the first argument and, if no error, returns 1 as the second.Replace a document that matches the _id of the document, or insert a document if no document matched the _id. This is done on the Apache CouchDB Server via a updateHandler ignoring the _rev field (hence behaviour is same as last-writer-wins). upsert is the same as calling update with the upsert option set to true, except that the return value of upsert is an object that contain the keys numberAffected and insertedId. (update returns only 1 if successful or 0 if not)Remove a document from the database.Argumentsid_id value of the document to be removedcallback FunctionOptional. If present, called with an error object as the first argument and, if no error, returns 1 as the second.Delete the document whose _id matches the specified value them from the database. This is done on the Apache CouchDB Server via a updateHandler ignoring the _rev field1 will be returned  when successful otherwise 0, if you don't pass a callback.Allow users to write directly to this database from client code, subject to limitations you define.optionsinsert, update, remove FunctionFunctions that look at a proposed modification to the database and return true if it should be allowed.fetch Array of StringsOptional performance enhancement. Limits the fields that will be fetched from the database for inspection by your update and remove functions.When a client calls insert, update, or remove on a database, the database's allow and deny callbacks are called on the server to determine if the write should be allowed. If at least one allow callback allows the write, and no deny callbacks deny the write, then the write is allowed to proceed.These checks are run only when a client tries to write to the database directly, for example by calling update from inside an event handler. Server code is trusted and isn't subject to allow and deny restrictions. That includes methods that are called with Meteor.call — they are expected to do their own access checking rather than relying on allow and deny.You can call allow as many times as you like, and each call can include any combination of insert, update, and remove functions. The functions should return true if they think the operation should be allowed. Otherwise they should return false, or nothing at all (undefined). In that case Meteor will continue searching through any other allow rules on the database.The available callbacks are:* insert(userId, doc)The user userId wants to insert the document doc into the database. Return true if this should be allowed. doc will contain the _id field if one was explicitly set by the client. You can use this to prevent users from specifying arbitrary _id fields.* update(userId, doc, modifiedDoc) The user userId wants to update a document doc. (doc is the current version of the document from the database, without the proposed update.) Return true to permit the change.  modifiedDoc is the doc submitted by the user.* remove(userId, doc) The user userId wants to remove doc from the database. Return true to permit this.When calling update or remove Meteor will by default fetch the entire document doc from the database. If you have large documents you may wish to fetch only the fields that are actually used by your functions. Accomplish this by setting fetch to an array of field names to retrieve.If you never set up any allow rules on a database then all client writes to the database will be denied, and it will only be possible to write to the database from server-side code. In this case you will have to create a method for each possible write that clients are allowed to do. You'll then call these methods with Meteor.call rather than having the clients call insert, update, and remove directly on the database.Override allow rules.optionsinsert, update, remove FunctionFunctions that look at a proposed modification to the database and return true if it should be denied, even if an allow rule says otherwise.This works just like allow, except it lets you make sure that certain writes are definitely denied, even if there is an allow rule that says that they should be permitted.When a client tries to write to a database, the Meteor server first checks the database's deny rules. If none of them return true then it checks the database's allow rules. Meteor allows the write only if no deny rules return true and at least one allow rule returns true.To create a cursor, use database.find. To access the documents in a cursor, use forEach, map, or fetch.Call callback once for each matching document, sequentially and synchronously.Argumentscallback FunctionFunction to call. It will be called with three arguments: the document, a 0-based index, and cursor itself.thisArg AnyAn object which will be the value of this inside callback.When called from a reactive computation, forEach registers dependencies on the matching documents.Map callback over all matching documents. Returns an Array.Argumentscallback FunctionFunction to call. It will be called with three arguments: the document, a 0-based index, and cursor itself.thisArg AnyAn object which will be the value of this inside callback.When called from a reactive computation, map registers dependencies on the matching documents.On the server, if callback yields, other calls to callback may occur while the first call is waiting. If strict sequential execution is necessary, use forEach instead.Return all matching documents as an Array.When called from a reactive computation, fetch registers dependencies on the matching documents.Returns the number of documents that match a query.Unlike the other functions, count registers a dependency only on the number of matching documents. (Updates that just change or reorder the documents in the result set will not trigger a recomputation.)Watch a query. Receive callbacks as the result set changes.Argumentscallbacks ObjectFunctions to call to deliver the result set as it changesThis follow same behaviour of mongo-livedata driverWatch a query. Receive callbacks as the result set changes. Only the differences between the old and new documents are passed to the callbacks.Argumentscallbacks ObjectFunctions to call to deliver the result set as it changesThis follow same behaviour of mongo-livedata driverThe simplest selectors are just a string. These selectors match the document with that value in its _id field.A slightly more complex form of selector is an object containing a set of keys that must match in a document:// Matches all documents where the name and cognomen are as given{name: \"Rhialto\", cognomen: \"the Marvelous\"}// Matches every documentBut they can also contain more complicated tests:// Matches documents where age is greater than 18{age: {$gt: 18}}Sorts maybe specified using the Cloudant sort syntax//Example[{\"Actor_name\": \"asc\"}, {\"Movie_runtime\": \"desc\"}]JSON array following the field syntax, described below. This parameter lets you specify which fields of an object should be returned. If it is omitted, the entire object is returned.// Example include only Actor_name, Movie_year and _id[\"Actor_name\", \"Movie_year\", \"_id\"]","url":"https://github.com/cloudant/meteor-couchdb","created_at":"2016-01-04 16:12:59 +00:00","updated_at":"","imageurl":"","status":"Live","languages":["JavaScript"],"technologies":["Cloudant","CouchDB"],"topic":["NoSQL"],"featured":"false","demourl":"","githuburl":"https://github.com/cloudant/meteor-couchdb","videourl":"","documentationurl":"","author":"","otherurl":"","level":"Intermediate","type":"Article","namespace":["Cloud Data Services"],"related_ids":[]}},
{"id":"202858438b62c8c9245f50fee59835d0b2e052ec","key":"202858438b62c8c9245f50fee59835d0b2e052ec","value":1,"doc":{"_id":"202858438b62c8c9245f50fee59835d0b2e052ec","_rev":"5-316594c63776c2b9d68b41500668a959","name":"Hybrid Cloud Tutorial Part 1: Create a Secure Gateway","full_name":"ibm-cds-labs/hybrid-cloud-tutorial","description":"See how easy it is to unlock your data for use in mobile and web applications, or for more flexible analysis and reporting. Bluemix Secure Gateway service lets you move data from on-premises to the cloud in a secure manner. ","body":"See how easy it is to unlock your data for use in mobile and web applications, or for more flexible analysis and reporting. Bluemix Secure Gateway service lets you move data from on-premises to the cloud in a secure manner. This is a multi-part tutorial which shows how to set up a gateway and then build an app on top of it. Here, in Part 1, we’ll cover:Lots of enterprises have valuable data they need to protect. To keep sensitive data secure, databases are often stored on-premises within an organization’s physical location, where staff can protect it more easily. But more and more, organizations also want to host data in the cloud for easy availability and integration with analytics and mobile or web apps. They're looking to take data out of their system of record and open it to one or more systems of engagement.Secure gateway lets you safely connect to an on-premises database. It works by creating a secure tunnel through which you can access protected data. The gateway encrypts and authenticates user connections, to prohibit unauthorized access. It’s a way to open your on-premises data to the cloud and enjoy the flexibility, security, and scalability that it offers.One gateway can connect to many on-premises data sources. In this tutorial, we're using Bluemix, IBM's cloud platform, to create the gateway. Here's a simplified version of what we're doing here in Part 1:We'll create a new Secure Gateway on Bluemix, which generates a gateway ID. We'll use that ID to start the gateway client in our on-premises network.Optional, but smart: You can add additional security by enforcing the use of a security token when starting the client.Create one or more destinations (data sources) to your on-prem database servers. Each destination will have its own port on the Bluemix server.Test the connection by accessing your data from your a browser or a bluemix app, through the url given for each destination.Here's how the different pieces connect together.In this tutorial, we’ll set up a secure gateway for access a sample Apache CouchDBTM database. The point of using CouchDB is to verify that the Secure Gateway instance works. You can replace it with any database of your choice to achieve the same results.Docker Engine is a lightweight runtime and packaging tool for apps.  Docker works best on Linux OS. If you want to use Docker on Mac or Windows, just install the helper app, Boot2Docker.  You’ll find all the details and instructions at  https://docs.docker.com/installation/#installation. Just choose your operating system and follow the  instructions.Now we’re ready to set up the gateway.Go to the Bluemix site: https://console.ng.bluemix.net/If you’re new to Bluemix, you can sign up for a free trial.Scroll down to Integration and click Secure Gateway.Tip: Most Bluemix services run entirely on the cloud. Secure Gateway is the rare exception to this rule, since its very purpose is to securely connect to on-prem data sources. So, it requires both cloud-platform-side and on-premises processes.On the upper right of the screen, click the APP dropdown and choose Leave unbound.Note: If you haven’t yet installed the Docker client, you must go do so now (see previous section).Enter any name you want for the gateway.Under How would you like to connect this gateway? choose Docker.Copy the text and, if you’re on Mac or Windows, add additional text:If you’re on Linux, this command works fine as-is. But for Mac and Windows, you need to insert the following additional text, right after docker runInsert spaces on either side. The beginning of the line should look like this:Go to your computer’s command line, paste in the text, and press Enter.Your gateway client is now connected to Bluemix.Connected! If you go back and open the gateway in Bluemix,status in the upper right corner shows as Connected.Leave your terminal command line window open. You’ll return to it in a few minutes.Next, we must set the data source endpoint. This will be the on-premises source database we want to share out to the cloud. For the purposes of this tutorial, we’ll use a simple CouchDB database.On your on-prem laptop or computer, install CouchDB.Return to Bluemix and open your open the gateway. Under Create Destinations Enter a name for the connection. Then enter the IP address and port of the on-prem machine where your couchDB database resides and click the +plus button on the far right of the line (use 127.0.0.1 if CouchDB is installed on the current laptop)If you're on Windows or Mac, configure Boot2Docker to provide access to the data.On Windows and Mac, you must allow access through multiple containers. To do so, open a new instance of Boot2Docker and run the following command--inserting your own IP and port information. (If couchDB is running on your local laptop, you can use 127.0.0.1 for the host and 5984 for the port, which are the default settings.)Now you'll see some results. Follow these steps to view your local couchDB data from outside your network.On a laptop or machine outside your on-premise network, open a browser and sign in to Bluemix.Locate the secure gateway connection you created and click its i information button.Open another browser window and paste the string into the address bar. At the end of the string, type /_utils so the address looks like this:You'll see your couchDB dashboard (Futon app) appear. That's it!  Your database is now accessible from outside your on-premises network!You saw it happen, and so did Bluemix. In Bluemix, return to or open the gateway. The chart shows a spike in traffic.Now you know how create a secure gateway that opens your on-prem data to the cloud. You can try these same steps  with  MYSQL, DB2, MongoDB, or any other databases you use on-premises.There are 2 types of security to consider. You can:* Require a security token when starting the gateway client. This is useful if you want to control who can start the gateway client. To do so, when you add the gateway, turn on the Enforce Security Token on Client checkbox.Once you do, you see the security token in Gateway details (beside the key icon) for use when starting the gateway on the client:* (Advanced) Extend TLS encryption between the gateway client and your on-prem data source. To implement, click the Enable client TLS checkbox located in the Advanced section of the destination configuration. Optionally, you can upload a certificate file (.pem extension). Note: You do not have to do this step if the certificate is self-signed....for additional parts of this tutorial which will show you how to build an app that leverages the secure gateway. After that, we'll learn how to include data sets from multiple sources (cloud-based and local) for combination and analysis.© \"Apache\", \"CouchDB\", \"Apache CouchDB\" and the CouchDB logo are trademarks or registered trademarks of The Apache Software Foundation. All other brands and trademarks are the property of their respective owners.","url":"https://github.com/ibm-cds-labs/hybrid-cloud-tutorial/blob/master/tutorial/tutorial.md","created_at":"2015-11-04 20:07:23 +00:00","updated_at":"2015-11-04 20:07:23 +00:00","imageurl":"","status":"Live","languages":[],"technologies":["Bluemix","CouchDB","Secure Gateway"],"topic":["Hybrid"],"featured":"false","demourl":"","githuburl":"https://github.com/ibm-cds-labs/hybrid-cloud-tutorial","videourl":"","documentationurl":"","author":"David Taieb","otherurl":"","level":"Intermediate","type":"Article","namespace":["Cloud Data Services"],"related_ids":[]}},
{"id":"4c304f1b5cdd1e25dcc6f9faa8b7cce53b96f523","key":"4c304f1b5cdd1e25dcc6f9faa8b7cce53b96f523","value":1,"doc":{"_id":"4c304f1b5cdd1e25dcc6f9faa8b7cce53b96f523","_rev":"3-bb357271dcd7cd8f8d56f9b0af7c956e","name":"CouchImport","full_name":"glynnbird/couchimport","description":"couchimport - CouchDB/Cloudant import tool to allow data to be bulk inserted","body":"CouchImport is designed to assist you with importing flat datainto CouchDB efficiently. It can be used either as command-line utilities couchimport and couchexport or the underlying functions can be used programatically: * simply pipe the data file to 'couchimport' on the command line * handles tab or comma separated data * uses Node.js's streams for memory efficiency * plug in a custom function to add your own changes before the data is written * writes the data in bulk for speed * can also write huge JSON files using a streaming JSON parser * allows multiple writes to happen at once using the --parallelism option","url":"https://github.com/glynnbird/couchimport","created_at":"2015-11-09 17:26:35 +00:00","updated_at":"2015-11-09 17:26:35 +00:00","imageurl":"https://avatars0.githubusercontent.com/u/697925?v=3&s=400","status":"Live","languages":["JavaScript"],"technologies":["Cloudant","CouchDB"],"topic":["ETL"],"featured":"false","demourl":"","githuburl":"https://github.com/glynnbird/couchimport","videourl":"","documentationurl":"","author":"Glynn Bird","otherurl":"","level":"Intermediate","type":"Article","namespace":["Cloud Data Services"],"related_ids":[]}},
{"id":"763001073c14f43bc827eb2c2f910eabb4e966b8","key":"763001073c14f43bc827eb2c2f910eabb4e966b8","value":1,"doc":{"_id":"763001073c14f43bc827eb2c2f910eabb4e966b8","_rev":"3-11d94652c68241b649aaf329e8fd3f50","name":"IBM Message Hub API","full_name":"ibm-messaging/message-hub-rest","description":"This Node.js module provides a high-level API by which you can interact with the REST API exposed by the Message Hub service.","body":"Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository * Watch 12 * Star 7 * Fork 4IBM-MESSAGING / MESSAGE-HUB-RESTCode Issues 0 Pull requests 0 Pulse Graphs No description or website provided. * 20 commits * 1 branch * 7 releases * Fetching contributors 1. JavaScript 100.0%JavaScript New file Find file HTTPS Choose a clone URL HTTPS (recommended) Clone with Git or checkout with SVN using the repository's web address. HTTPS Learn more about clone URLs Download ZIP Branch: master Switch branches/tags * Branches * Tagsmaster Nothing to show 1.1.1 1.1.0 1.0.4 1.0.3 1.0.2 1.0.1 1.0.0 Nothing to show New pull request Latest commit a45d466 Apr 12, 2016 niall-weedon Update npm package version to 1.1.2, update message parsing Permalink Failed to load latest commit information. lib Update npm package version to 1.1.2, update message parsing Apr 12, 2016 test Update npm package version to 1.1.1, update produce function to handl… Apr 7, 2016 .gitignore Library 1.0.0 Commit Oct 14, 2015 LICENSE Library 1.0.0 Commit Oct 14, 2015 README.md Update npm package version to 1.1.1, update produce function to handl… Apr 7, 2016 package.json Update npm package version to 1.1.2, update message parsing Apr 12, 2016README.MDIBM MESSAGE HUB REST API CLIENT MODULEIBM Message Hub is a scalable, distributed, high throughput message bus to uniteyour on-premise and off-premise cloud technologies. You can wire micro-servicestogether using open protocols, connect stream data to analytics to realisepowerful insight and feed event data to multiple applications to react in realtime.This Node.js module provides a high-level API by which you can interact with theREST API exposed by the Message Hub service.GETTING STARTEDPREREQUISITESYou will need a Node.js 0.12.x runtime environment to use this module. This canbe installed from http://nodejs.org/download/ , or by using your operating system's package manager.INSTALLATION INSTRUCTIONSInstalling using npm:npm install message-hub-restRUN TESTS * To run against a mock Kafka service, use npm test * Important Note : Running tests against a live service (with the '--real' flag) is will   incur a fee and as such is not recommended.EXAMPLE USAGE:The following example sets up a connection to the Message Hub REST API, createsa topic, consumer and producer, then produces and consumes a few messages beforeexiting.var MessageHub =require('message-hub-rest');var services =process.env.VCAP_SERVICES;var instance =newMessageHub(services);var consumerInstance;var topicName ='mytopic';instance.topics.create(topicName)  .then(function(response) {      returninstance.consume('my_consumer_group', 'my_consumer_instance', { 'auto.offset.reset':'largest' });  })  .then(function(response) {    consumerInstance = response[0];  })  .fail(function(error) {    thrownewError(error);  });var receivedMessages =0;var produceInterval =setInterval(function() {  var list =newMessageHub.MessageList([    \"This is the message text\"  ]);  instance.produce('mytopic', list.messages)    .then(function() {      returnconsumerInstance.get('mytopic');    })    .then(function(data) {      console.log(data);      receivedMessages++;      if(receivedMessages >=3) {        clearInterval(produceInterval);        returnconsumerInstance.remove();      }    })    .fail(function(error) {      thrownewError(error);    });}, 1000);APIMESSAGEHUB(SERVICES, [OPTS])Constructs a new Client object, provided with Bluemix VCAP_SERVICES andadditional options used to help connect to a particular service. * services - (Object) VCAP_SERVICES of your Bluemix Message Hub service. * opts - (Object) Optional configuration options used when connecting to the   service. Properties include: * https , (Boolean) (optional), make HTTPS requests to the service. Defaults to      true, should only be set to false when testing against a mock Kafka      service.      Instantiate with the new keyword. When instantiated correctly, a new MessageHub/Client object will bereturned. Throws an error with an accompanying message if the provided servicesinformation is incorrect.MESSAGEHUB.PROTOTYPE.TOPICS.GET()Retrieves a list of all topics connected to the provided API key.Returns a Promise object which will be fulfilled when the request to the serviceresolves.MESSAGEHUB.PROTOTYPE.TOPICS.CREATE(TOPIC, PARTITIONS)Creates a topic of the specified name. Important Note : Creating topics incurs a fee - check the Bluemix documentation for moreinformation. * topic - (String) (required), the topic name for the service to create. * partitions - (String) (optional), the number of partitions to use for this topic.   Defaults to 1.Returns a Promise object which will be fulfilled when the request to the serviceresolves.MESSAGEHUB.PROTOTYPE.TOPICS.DELETE(TOPIC)Deletes a topic of the specified name. * topic - (String) (required), the topic name to delete from the service.Returns a Promise object which will be fulfilled when the request to the serviceresolves.MESSAGEHUB.PROTOTYPE.PRODUCE(TOPIC, MESSAGE)Produces a message on the specified topic. * topic - (String) (required), the topic name for the new messages to be produced   on. * message - (String|Array|MessageHub.MessageList|Object) (required), the message   object to be pushed to the service.Returns a Promise object which will be fulfilled when the request to the serviceresolves.MESSAGEHUB.PROTOTYPE.CONSUME(GROUPNAME, INSTANCENAME, [OPTIONS])Configures a consumer instance of the specified name. * groupName - (String) (required), the name of the consumer group. If the group doesn't   exist, one is created. * instanceName - (String) (required), the name of the consumer group instance. * options - (Object) (optional), additional options which can be provided to configure   the consumer group.Returns an instance of MessageHub.ConsumerInstance .MESSAGEHUB.CONSUMERINSTANCE(CLIENT, GROUPNAME, INSTANCENAME, [OPTIONS],[CONFIGURE])Constructs a new ConsumerInstance object. Usually not created directly, it isrecommended to use Client.prototype.consume . * groupName - (String) (required), the name of the consumer group. If the group doesn't   exist, one is created. * instanceName - (String) (required), the name of the consumer group instance. * options - (Object) (optional), additional options which can be provided to configure   the consumer group. * configure - (Boolean) (optional), flag used to automatically configure the instance.   Defaults to true.Returns an instance of MessageHub.ConsumerInstance .MESSAGEHUB.CONSUMERINSTANCE.PROTOTYPE.CONFIGURE()Configures the consumer instance by sending a request to the Kafka REST service.Returns a Promise object which will be fulfilled when the request to the serviceresolves.MESSAGEHUB.CONSUMERINSTANCE.PROTOTYPE.GET(TOPICNAME [TOVALUE])Retrieves a message from the provided topic name. * topicName - (String) (required), the topic to retrieve messages from. * toValue - (Boolean) (optional), unwraps base64 encoded messages, if true. Defaults   to true.Returns a Promise object which will be fulfilled when the request to the serviceresolves.MESSAGEHUB.CONSUMERINSTANCE.PROTOTYPE.REMOVE()Removes the current consumer instance from the server.Returns a Promise object which will be fulfilled when the request to the serviceresolves.MESSAGEHUB.MESSAGELIST([INIT])Constructs a new instances of the MessageList class. An initial array of valuescan be provided to pre-populate the list with messages. * init - (Array) (optional), array of values to be added to the list of messages.Returns an instance of MessageHub.MessageList , which allows for chaining of other methods.MESSAGEHUB.MESSAGELIST.PROTOTYPE.LENGTHReturns the number of messages in the message list.MESSAGEHUB.MESSAGELIST.PROTOTYPE.MESSAGESReturns the list of messages added to the MessageList instance.MESSAGEHUB.MESSAGELIST.PROTOTYPE.PUSH(MESSAGE)Convenience wrapper to add messages to 'messages.records'. Also converts allvalues to base64 strings so they can be sent through the service. * message - (String) (required), the message to be added to the list.Returns the current MessageHub.MessageList instance, which allows for chaining other methods.MESSAGEHUB.MESSAGELIST.PROTOTYPE.POP()Convenience wrapper for 'messages.records.pop()', but returns the currentMessageList instance to allow chaining of methods.Returns the current MessageHub.MessageList instance, which allows for chaining other methods.MESSAGEHUB.MESSAGELIST.PROTOTYPE.GET(INDEX)Retrieves a message from the message list, converting it back to its originalrepresentation (i.e. JSON string -> object) * index - (number) (required) The index of the list to retrieve.Returns the original representation of value stored in records array. * Status * API * Training * Shop * Blog * About * © 2016 GitHub , Inc. * Terms * Privacy * Security * Contact * HelpSomething went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session.","url":"https://github.com/ibm-messaging/message-hub-rest","created_at":"2015-11-19 15:19:08 +00:00","updated_at":"2015-11-19 15:19:08 +00:00","imageurl":"https://avatars3.githubusercontent.com/u/6453649?v=3&s=400","status":"Live","languages":["JavaScript","Node.js"],"technologies":["Kafka","Message Hub"],"topic":["Microservices"],"featured":"false","demourl":"","githuburl":"https://github.com/ibm-messaging/message-hub-rest","videourl":"","documentationurl":"","author":"","otherurl":"","level":"Beginner","type":"Article","namespace":["Cloud Data Services"],"related_ids":[]}},
{"id":"8faddf223dac8d489c05b113a5a215ac364815c3","key":"8faddf223dac8d489c05b113a5a215ac364815c3","value":1,"doc":{"_id":"8faddf223dac8d489c05b113a5a215ac364815c3","_rev":"2-4548ee5a88d522134586ec3a3c2efef6","name":"Update Cloudant document properties with Python","full_name":"Update Cloudant document properties with Python","description":"Loop through all docs in a Cloudant database and update data. This version changes string values to integers but it can easily be adapted for other uses.","body":"\r\n\r\n * Star 0\r\n * Fork 0\r\n\r\nRAJRSINGH / UPDATEPROPS.PY LAST ACTIVE JUL 26, 2016\r\nEmbed What would you like to do? Embed Embed this gist in your website. Embed Share Copy sharable URL for this gist. Share Clone via HTTPS Clone with Git or checkout with SVN using the repository's web address. HTTPS Learn more about clone URLs Download ZIP Code Revisions 3 Loop through all docs in a Cloudant database and update data. This version\r\nchanges string values to integers but it can easily be adapted for other uses. Raw updateprops.py import os from cloudant import cloudant from cloudant.client import Cloudant from cloudant.document import Document CLOUDANT_USERNAME = os.getenv( ' CLOUDANT_USERNAME ' , ' myusername ' ) CLOUDANT_PW = os.getenv( ' CLOUDANT_PW ' , ' mypw ' ) CLOUDANT_DB = ' mydb ' PROPS = [ ' rec ' , ' r ' , ' h ' , ' m ' , ' s ' , ' idts ' , ' idvc ' , ' idn ' , ' refts ' ] with cloudant( CLOUDANT_USERNAME , CLOUDANT_PW , account = CLOUDANT_USERNAME ) as client: mcdb = client[ CLOUDANT_DB ] for doc in mcdb: print ( \" Checking \" + doc[ ' _id ' ] + \" viewts: \" + str (doc[ ' viewts ' ])) if type (doc[ ' viewts ' ]) is unicode : print ( \" Got a bad one. \" ) for prop in PROPS : if ( type (doc[prop] is str or type (doc[prop]) is unicode ) ): if ( doc[prop] == ' null ' ): doc[prop] = None else : doc[prop] = int (doc[prop]) doc.save() ; print ( \" Saved \" + doc[ ' _id ' ]) Sign up for free to join this conversation on GitHub . Already have an account? Sign in to comment * Contact GitHub\r\n * API\r\n * Training\r\n * Shop\r\n * Blog\r\n * About\r\n\r\n * © 2016 GitHub , Inc.\r\n * Terms\r\n * Privacy\r\n * Security\r\n * Status\r\n * Help\r\n\r\nSomething went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session.","url":"https://gist.github.com/rajrsingh/a0cf7afc4e1c901734580471b04c02e1","created_at":"2016-07-26 15:38:56 +00:00","updated_at":"2016-07-26 15:41:31 +00:00","imageurl":"https://avatars0.githubusercontent.com/u/3768695?v=3&s=400","status":"Live","languages":["Python"],"technologies":["Cloudant"],"topic":["ETL","Data Science"],"featured":"false","demourl":"","githuburl":"https://gist.github.com/rajrsingh/a0cf7afc4e1c901734580471b04c02e1","videourl":"","documentationurl":"","author":"Raj Singh","otherurl":"","level":"Beginner","type":"Sample","namespace":["Cloud Data Services"],"related_ids":[]}},
{"id":"94a3c4681f05dda2f5d1e1abe4a2780ebb9b1219","key":"94a3c4681f05dda2f5d1e1abe4a2780ebb9b1219","value":1,"doc":{"_id":"94a3c4681f05dda2f5d1e1abe4a2780ebb9b1219","_rev":"3-eeb600ec801e8e527348da124ab07567","name":"PouchDB","full_name":"PouchDB is a pocket-sized database","description":"PouchDB is an open-source JavaScript database inspired by Apache CouchDB that is designed to run well within the browser.","body":"PouchDB is an open-source JavaScript database inspired by Apache CouchDB that is designed to run well within the browser.PouchDB was created to help web developers build applications that work as well offline as they do online.To get started using PouchDB, check out the web site and API documentation.The PouchDB community is active on Freenode IRC, Slack,in the Google Groups mailing list, and on StackOverflow. Or you can tweet @pouchdb!If you think you've found a bug in PouchDB, please write a reproducible test case and file a Github issue. We recommend bl.ocks.org for code snippets, because some iframe-based services like JSFiddle and JSBin do not support IndexedDB in all browsers. You can start with this template.If you like to live on the bleeding edge, you can find the PouchDB nightly builds at pouchtest.com/nightly.PouchDB follows semantic versioning. To see a changelog with all PouchDB releases, check out the Github releases page.For a concise list of breaking changes, there's the wiki list of breaking changes.Keep in mind that PouchDB is auto-migrating, so a database created in 1.0.0 will still work if you open it in 4.0.0+. Any release containing a migration is clearly marked in the release notes.We're always looking for new contributors! If you'd like to try your hand at writing code, writing documentation, designing the website, writing a blog post, or answering questions on StackOverflow, then we'd love to have your input.If you have a pull request that you'd like to submit, please read the contributing guide for info on style, commit message format, and other (slightly!) nitpicky things like that. PouchDB is heavily tested, so you'll also want to check out the testing guide.","url":"https://github.com/pouchdb/pouchdb","created_at":"2016-04-29 18:30:24 +00:00","updated_at":"","imageurl":"","status":"Live","languages":["JavaScript","Node.js"],"technologies":["CouchDB","PouchDB"],"topic":["NoSQL","Offline"],"featured":"false","demourl":"","githuburl":"https://github.com/pouchdb/pouchdb","videourl":"","documentationurl":"","author":"","otherurl":"","level":"Intermediate","type":"Article","namespace":["Cloud Data Services"],"related_ids":[]}},
{"id":"a64853ce5164240cd75904da828f156ef8132eb1","key":"a64853ce5164240cd75904da828f156ef8132eb1","value":1,"doc":{"_id":"a64853ce5164240cd75904da828f156ef8132eb1","_rev":"2-4928a0761cbbb60dbb7a452f90f9750e","name":"bluemix-helper-config","full_name":"ibm-cds-labs/bluemix-helper-config","description":"Bluemix Helper for managing config. Also lets you run and debug your application locally while running against services deployed on Bluemix","body":"Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository * Watch 14\n * Star 0\n * Fork 0\n\nIBM-CDS-LABS / BLUEMIX-HELPER-CONFIG\nCode Issues 0 Pull requests 0 Pulse Graphs Bluemix Helper for managing config * 22 commits\n * 4 branches\n * 0 releases\n * 3 contributors\n\n 1. JavaScript 100.0%\n\nJavaScript New file Find file HTTPS Choose a clone URL HTTPS (recommended) Clone with Git or checkout with SVN using the repository's web address. HTTPS Learn more about clone URLs Download ZIP Branch: master Switch branches/tags * Branches\n * Tags\n\nbluemix-helper-config-updates i2 log_console_stream master Nothing to show Nothing to show New pull request Latest commit 2588996 Feb 22, 2016 DTAIEB Fixed bug with id not set Permalink Failed to load latest commit information. lib Fixed bug with id not set Feb 22, 2016 .gitignore Initial commit Aug 24, 2015 README.md Updated Readme Sep 6, 2015 package.json Fixed bug with id not set Feb 23, 2016README.MD\nBLUEMIX-HELPER-CONFIG\nnodejs helper library that makes it easier to access services bound to your\napplication. It also lets you run and debug your application locally while\nrunning against services deployed on Bluemix.\n\nVCAPSERVICES\nYou can easily access the services bound to your application by using the\nvcapServices object as follow:\n\n...var bluemixHelperConfig =require('bluemix-helper-config'); //helper config to locate sso service   var vcapServices =bluemixHelperConfig.vcapServices;\n...//Locate the cloudant service by using regular expression (The name doesn't have to match exactly and search is case insensitive)  var cloudantService =vcapServices.getService( \"cloudant\" );  \nif ( cloudantService ) {  \n  //Use the service credentials to access the cloudant databasevar cloudant =require('cloudant')({\n        \"url\":cloudantService.credentials.url\n    });\n  ....\n}else{\n    thrownewError(\"Unable to find cloudant Service\");\n}\n...\n\nWhen building a Bluemix application that depends on services, it is recommended\nto not hard-code the name of the service as to allow the user to reuse services\nthat have already been deployed. For this reason, the vcapServices is using\nregular expressions to loosen the requirements on the name. You could also let\nuser specify the name of the service using configManager object (see next\nsection for more details) e.g.\n\n...var bluemixHelperConfig =require('bluemix-helper-config'); \nvar vcapServices =bluemixHelperConfig.vcapServices;\nvar configManager =bluemixHelperConfig.configManager;\n...var cloudantService =vcapServices.getService( configManager.get(\"SERVICE_NAME\") ||\"cloudant\" );  \n...\n\nCONFIGMANAGER\nconfigManager provide an abstraction layer that enable the user to specify\nconfiguration variables in a flexible way. When searching for a configuration\nkey, the framework will first look in the environment variables (For example, on\nlinux you can use \"export VAR=value\" or on Windows \"set VAR=value\"). If not\nfound, the system will look in the json configuration as defined by the nconf library.\n\nUsing nconfig json configuration, you can easily run and debug your application\nlocally against the services running on Bluemix by importing the vcapServices\njson snippet as follow: (For a detailed example on how to set up the sample data\npipes project to run locally see this page )\n\n 1. In the Bluemix instance, go to the Environment Variables page of your app.\n 2. Go to the VCAP_SERVICES tab and click on the copy icon on the top right\n    (we'll use that in the step below)\n    \n 3. In your local machine, create a folder of your choice (e.g.\n    /Users/dtaieb/myConfig1 ).\n    Note: this folder is private to your environment, make sure to separate it\n    from the project directory so you don't accidentally commit the data into a\n    source repository.\n    \n 4. Set an environment variable called NODE_CONFIG that point to the config\n    directory e.g export NODE_CONFIG = /Users/dtaieb/myConfig1\n 5. Create a file called vcap.json in the private folder, create a JSON\n    structure that has a field named DEV_VCAP_CONFIG with a value corresponding\n    to the content of the VCAP_SERVICES you copied from the step above. eg:\n    \n        {\"DEV_VCAP_CONFIG\":\n            {\n               \"cloudantNoSQLDB\": [\n                  {\n                     \"name\":\"pipes-cloudant-service\",\n                     \"label\":\"cloudantNoSQLDB\",\n                     \"plan\":\"Shared\",\n                     \"credentials\": {\n                        ...\n                     }\n                  }\n               ],\n               \"dashDB\": [\n                  {\n                     \"name\":\"pipes-dashdb-service\",\n                     \"label\":\"dashDB\",\n                     \"plan\":\"Entry\",\n                     \"credentials\": {\n                        ...\n                     }\n                  }\n               ],\n               \"DataWorks\": [\n                  {\n                     \"name\":\"pipes-dataworks-service\",\n                     \"label\":\"DataWorks\",\n                     \"plan\":\"free\",\n                     \"credentials\": {\n                       ...\n                     }\n                  }\n               ]\n            }\n        }\n    \n    \n 6. Create a file called myapp.json in the same directory with the configuration\n    key/value pairs you application requires e.g:\n    \n    {\n        \"DEV_PORT\":8082,\n        \"CONFIG1\":\"value1\"\n    }\n    \n    Note: you can also use a different name for the app by specifying an\n    environment variable called APP_NAME e.g export APP_NAME=anotherName\n    \n    \n 7. Export the following variable: NODE_CONFIG=<path to your private directory>\n    e.g. NODE_CONFIG=/Users/dtaieb/myConfig1\n    \n 8. When running locally, you must export the following variable: HOME=<path to\n    your home directory> e.g: HOME=/Users/dtaieb\n    \n\nYou are now ready to use these variables in your code. Note that the\nvcapServices object is already using this framework, the call to\nvcapService.getService will look in vcap.json if defined, thus letting you\nrun/debug your application against services deployed on Bluemix\n\n...var bluemixHelperConfig =require('bluemix-helper-config'); \nvar configManager =bluemixHelperConfig.configManager;\n...var config1 =configManager.get(\"CONFIG1\");\nvar port =configManager.get(\"DEV_PORT\")  \n...\n\nYou can now define as many configuration directories as you'd like (say against\nmultiple bluemix spaces) and easily switch between them using the NODE_CONFIG\nenvironment variable. This can be very useful when running automated tests.\n\n * Status\n * API\n * Training\n * Shop\n * Blog\n * About\n\n * © 2016 GitHub , Inc.\n * Terms\n * Privacy\n * Security\n * Contact\n * Help\n\nSomething went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session.","url":"https://github.com/ibm-cds-labs/bluemix-helper-config","created_at":"2015-11-19 15:19:34 +00:00","updated_at":"2015-11-19 15:19:34 +00:00","imageurl":"https://avatars0.githubusercontent.com/u/12701847?v=3&s=400","status":"Live","languages":["JavaScript","Node.js"],"technologies":["Bluemix"],"topic":[],"featured":"false","demourl":"","githuburl":"https://github.com/ibm-cds-labs/bluemix-helper-config","videourl":"","documentationurl":"","author":"David Taieb","otherurl":"","level":"Beginner","type":"Article","namespace":["Cloud Data Services"],"related_ids":[]}},
{"id":"af08d40e542dbacdf55d37d236fc085c12796b31","key":"af08d40e542dbacdf55d37d236fc085c12796b31","value":1,"doc":{"_id":"af08d40e542dbacdf55d37d236fc085c12796b31","_rev":"2-e1b7c52b1ccd62f65735b30e2ecfa023","name":"Cloudant load tester","full_name":"A simple Node.js script to test Cloudant geo queries for load and/or coverage.","description":"A simple Node.js script to test Cloudant geo queries for load and/or coverage. `npm install superagent` then `node geotest.js`","body":"Skip to content * All gists\r\n * GitHub\r\n\r\nSign up for a GitHub account Sign in Create a gist nowInstantly share code, notes, and snippets.\r\n\r\n * Star 0\r\n * Fork 0\r\n\r\nRAJRSINGH / GEOTEST.JS LAST ACTIVE JUL 25, 2016\r\nEmbed What would you like to do? Embed Embed this gist in your website. Embed Share Copy sharable URL for this gist. Share Clone via HTTPS Clone with Git or checkout with SVN using the repository's web address. HTTPS Learn more about clone URLs Download ZIP Code Revisions 2 A simple Node.js script to test Cloudant geo queries for load and/or coverage.\r\n`npm install superagent` then `node geotest.js` Raw geotest.js var request = require ( ' superagent ' ); // Replace these 3 variables with your own information // Note: The database must be world readable const CLOUDANT_ACCOUNT = ' opendata ' ; const CLOUDANT_DB = ' pois ' ; const GEO_INDEX = ' _design/idx/_geo/spatial ' ; for ( var index = 0 ; index < 500 ; index ++ ) { runQuery (index) } function runQuery ( idx ) { const t = new Date (); console . log ( \" here's the start time on run \" + idx + \" : \" + t . toISOString ()); var rlat = ( Math . random () * 180 ) - 90 ; // cover the globe // var rlat = (Math.random() * 18) +31; // cover only the US var rlon = ( Math . random () * 360 ) - 180 ; // cover the globe // var rlon = (Math.random() * 51) - 123; // var rrad =\r\nMath.floor(100*(Math.random() * 8) - 2); // cover only the US var rrad = Math . floor ( 10000 * (( Math . random () * 5 ) + 7 )); // 7000 to 12000 meters var url = ' https:// ' + CLOUDANT_ACCOUNT + ' .cloudant.com ' ; url += ' / ' + CLOUDANT_DB + ' / ' + GEO_INDEX ; url += ' ?limit=200&relation=contains&lat= ' + rlat + ' &lon= ' + rlon + ' &radius= ' + rrad; request . get (url) . set ( ' Accept ' , ' application/json ' ) . end ( function ( err , res ) { console . log ( ' REQUEST: ' + url); var te = new Date (); var diff = new Date ( te . getTime () - t . getTime ()); // console.log(\"here's the end time on run \" + idx + \":  if (err || ! res . ok ) { console . log ( ' Oh no! error ' ); } else { console . log ( ' Run ' + idx + ' : ' + res . body . rows . length + ' rows returned in ' + diff / 1000 + ' seconds \\n ' ); } }); } Sign up for free to join this conversation on GitHub . Already have an account? Sign in to comment * Contact GitHub\r\n * API\r\n * Training\r\n * Shop\r\n * Blog\r\n * About\r\n\r\n * © 2016 GitHub , Inc.\r\n * Terms\r\n * Privacy\r\n * Security\r\n * Status\r\n * Help\r\n\r\nSomething went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session.","url":"https://gist.github.com/rajrsingh/06720f82a5d3957c201ced84f8834b16","created_at":"2016-07-26 15:43:47 +00:00","updated_at":"2016-07-26 15:45:34 +00:00","imageurl":"https://avatars0.githubusercontent.com/u/3768695?v=3&s=400","status":"Live","technologies":["Cloudant"],"topic":["ETL","Mobile"],"featured":"true","demourl":"","githuburl":"https://gist.github.com/rajrsingh/06720f82a5d3957c201ced84f8834b16","videourl":"","documentationurl":"","author":"Raj Singh","otherurl":"","level":"Beginner","type":"Sample","namespace":["Cloud Data Services"],"languages":[],"related_ids":[]}},
{"id":"ce262725668f3a97fcffc07a9d93c4ed2f4cf4d1","key":"ce262725668f3a97fcffc07a9d93c4ed2f4cf4d1","value":1,"doc":{"_id":"ce262725668f3a97fcffc07a9d93c4ed2f4cf4d1","_rev":"3-c784f000a90af4802be4caea3c3f77d5","name":"FieldWork","full_name":"FieldWork","description":"fieldwork - Sample app demonstrating offline synchronization of geospatial data, spatial editing and mapping with Cloudant","body":"Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository * Watch 18\r\n * Star 6\r\n * Fork 3\r\n\r\nIBM-CDS-LABS / FIELDWORK\r\nCode Issues 0 Pull requests 0 Pulse Graphs Sample app demonstrating offline synchronization of geospatial data, spatial\r\nediting and mapping with Cloudant http://fieldwork.mybluemix.net * 46 commits\r\n * 1 branch\r\n * 0 releases\r\n * 3 contributors\r\n\r\n 1. JavaScript 52.5%\r\n 2. HTML 24.0%\r\n 3. CSS 23.5%\r\n\r\nJavaScript HTML CSS Clone or downloadCLONE WITH HTTPS\r\nUse Git or checkout with SVN using the web URL.\r\n\r\nDownload ZIP Find file Branch: master Switch branches/tags * Branches\r\n * Tags\r\n\r\nmaster Nothing to show Nothing to show New pull request Latest commit b677fa5 May 31, 2016 rajrsingh no longer need to parse JSON from text into an object Permalink Failed to load latest commit information. .bluemix added Ingredients and added output compression support May 31, 2016 public no longer need to parse JSON from text into an object May 31, 2016 .cfignore ignore node modules Sep 2, 2015 .gitignore fixed edit database issues Nov 19, 2015 LICENSE.txt fixed edit database issues Nov 19, 2015 README.md updates for new deployment tracker May 24, 2016 admin.js Merge remote-tracking branch 'rajrsingh/master' Dec 14, 2015 app.js no longer need to parse JSON from text into an object May 31, 2016 fieldwork-app-graphics.png expanded architecture Mar 10, 2016 manifest.yml updates for new deployment tracker May 24, 2016 mapconfig.json fixed edit database issues Nov 19, 2015 package.json added Ingredients and added output compression support May 31, 2016 testdata.js point to fork at ibm-cds-labs Aug 28, 2015README.MD\r\nFIELD WORK\r\nField Work is a web application that supports offline editing and mapping of geospatial\r\ndata. This app:\r\n\r\n * downloads and saves geospatial data locally for offline use by Cloudant Geo\r\n   or Lucene Geo query\r\n * has a UI that supports editing of points, lines, and polygons\r\n * syncs locally-edited data back to an IBM Cloudant database\r\n\r\nMany field-based industries whose personnel are disconnected from communications\r\nnetworks—often in remote areas or even underground—can benefit from this kind of\r\noffline-first mobile application. This demonstration is designed for utilities\r\nrepair personnel who need to capture events in work orders.\r\n\r\n\r\n\r\nRELATED RESOURCES\r\n * Blog post: Better infrastructure maintenance with offline mobile maps\r\n   \r\n   \r\n * Presentation: Field Work: Map-centric mobile apps with Cloudant Geo and\r\n   LeafletJS\r\n   \r\n   \r\n\r\nTRY IT\r\nPlay with the live demo version of this app . To get started:\r\n\r\n 1. Drag the map to an area you want to see.\r\n 2. Click the Load Data button.\r\n 3. On the upper right of the map, choose the data types you want to see.\r\n 4. In the left pane, click the Edit Pins button. Pushpins appear on the map.\r\n 5. On the left side of the map, use the controls that appear to edit and add\r\n    pins. (Hover over a control for guidance.)\r\n\r\n\r\n\r\nARCHITECTURE\r\n\r\n\r\nThis an architectural overview of the components that make this app run.\r\n\r\nDEPLOY TO IBM BLUEMIX\r\nThe fastest way to deploy this application to Bluemix is to click this Deploy to Bluemix button. If you prefer instead to deploy manually to Bluemix then skip ahead to\r\nthe Manual Development section.\r\n\r\n\r\n\r\nDon't have a Bluemix account? If you haven't already, you'll be prompted to sign up for a Bluemix account when you click the button. Sign up, verify your email\r\naddress, then return here and click the the Deploy to Bluemix button again. Your new credentials let you deploy to the platform and also to\r\ncode online with Bluemix and Git. If you have questions about working in\r\nBluemix, find answers in the Bluemix Docs .\r\n\r\n(OPTIONAL) CUSTOMIZE THE APP URL\r\nBluemix creates a random, unique URL for your app, each time you deploy. If you\r\nwant to customize and set a static URL, you can do so in the IBM Bluemix DevOps Services project created for you when you deployed.\r\n\r\n 1. On the Bluemix Deployment Successful screen, click the Edit Code button.\r\n 2. Find and open the manifest.yml file.\r\n 3. Change the line random-route: true to host: my-unique-app-name\r\n    \r\n    On the next deployment, the URL for your app will be my-unique-app-name.mybluemix.net\r\n    \r\n    \r\n\r\nIf you plan to modify the code for this app, and want to use GitHub's code\r\nrepository ( instead of IBM Bluemix DevOps Services ), follow the instructions in the next section.\r\n\r\nMANUAL DEVELOPMENT\r\n 1. Fork the repo Click the Fork button in the top right corner of this repository\r\n    \r\n    \r\n 2. Create a Bluemix Account\r\n    \r\n    for Bluemix, or use an existing account.\r\n    \r\n    \r\n 3. Download and install the tool.\r\n    \r\n    \r\n 4. Clone the app to your local environment from your terminal using the\r\n    following command\r\n    \r\n    git clone https://github.com/ibm-cds-labs/fieldwork\r\n    \r\n    \r\n    \r\n 5. cd into your newly created directory.\r\n    \r\n    \r\n 6. Edit the manifest.yml file and change the <application-host> to something unique.\r\n    \r\n    ---\r\n    declared-services: \r\n      cloudant-fieldwork-db:\r\n        label: cloudantNoSQLDB\r\n        plan: Shared\r\n    applications:\r\n      - name: fieldwork\r\n        host: fieldwork-gr8one\r\n        memory: 128M\r\n        disk_quota: 512M\r\n        path: .\r\n        domain: mybluemix.net\r\n        instances: 1\r\n        services:\r\n        - cloudant-fieldwork-db\r\n    \r\n    \r\n    The host you use determines your application url initially, e.g. <application-host>.mybluemix.net .\r\n    \r\n    \r\n 7. Connect to Bluemix in your command-line tool and follow the prompts to log\r\n    in.\r\n    \r\n    $ cf api https://api.ng.bluemix.net\r\n    $ cf login\r\n    \r\n    \r\n    \r\n 8. Create the Cloudant service in Bluemix.\r\n    \r\n    $ cf create-service cloudantNoSQLDB Shared cloudant-fieldwork-db\r\n    \r\n    \r\n    \r\n\r\nMANUAL DEPLOYMENT\r\nTo deploy to Bluemix, simply:\r\n\r\n  $ cf push\r\n\r\n\r\nPRIVACY NOTICE\r\nThe Field Work sample web application includes code to track deployments to Bluemix and other\r\nCloud Foundry platforms. The following information is sent to a Deployment Tracker service on each deployment:\r\n\r\n * Application Name (application_name)\r\n * Space ID (space_id)\r\n * Application Version (application_version)\r\n * Application URIs (application_uris)\r\n\r\nThis data is collected from the VCAP_APPLICATION environment variable in IBM\r\nBluemix and other Cloud Foundry platforms. This data is used by IBM to track\r\nmetrics around deployments of sample applications to IBM Bluemix. Only\r\ndeployments of sample applications that include code to ping the Deployment\r\nTracker service will be tracked.\r\n\r\nDISABLING DEPLOYMENT TRACKING\r\nYou can disable deployment tracking by removing ./admin.js track && from the install line of the scripts sections within package.json .\r\n\r\nLICENSE\r\nLicensed under the Apache License, Version 2.0 .\r\n\r\nField Work is a sample application created for the purpose of demonstrating an\r\noffline geographic data sync and editing application. The program is provided\r\nas-is with no warranties of any kind, express or implied.\r\n\r\n * Contact GitHub\r\n * API\r\n * Training\r\n * Shop\r\n * Blog\r\n * About\r\n\r\n * © 2016 GitHub , Inc.\r\n * Terms\r\n * Privacy\r\n * Security\r\n * Status\r\n * Help\r\n\r\nSomething went wrong with that request. Please try again. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session.","url":"https://github.com/ibm-cds-labs/fieldwork","created_at":"2016-08-01 20:13:42 +00:00","updated_at":"2016-08-01 20:23:41 +00:00","imageurl":"https://avatars0.githubusercontent.com/u/12701847?v=3&s=400","status":"Live","languages":["JavaScript"],"technologies":["Bluemix","Cloudant"],"topic":["IoT","Location","Offline","Open Data"],"featured":"true","demourl":"","githuburl":"https://github.com/ibm-cds-labs/fieldwork","videourl":"","documentationurl":"","author":"","otherurl":"","level":"Beginner","type":"Demo","namespace":["Cloud Data Services"],"related_ids":[]}},
{"id":"d5f858b3722955a4615e365a30d626707a6c86b2","key":"d5f858b3722955a4615e365a30d626707a6c86b2","value":1,"doc":{"_id":"d5f858b3722955a4615e365a30d626707a6c86b2","_rev":"2-96635f8a476acb05d227fc46daef635b","name":"pixiedust","full_name":"pixiedust","description":"Pixiedust is an open source Python helper library that works as an add-on to Jupyter notebooks to improve the user experience of working with data. It also provides extra capabilities that fill a gap when the notebook is hosted on the cloud and the user has no access to configuration files.","body":"Skip to content Personal Open source Business Explore Sign up Sign in Pricing Blog Support Search GitHub This repository * Watch 15\r\n * Star 5\r\n * Fork 2\r\n\r\nIBM-CDS-LABS / PIXIEDUST\r\nCode Issues 1 Pull requests 0 Pulse Graphs Python Helper library for Spark IPython Notebooks * 95 commits\r\n * 2 branches\r\n * 0 releases\r\n * 7 contributors\r\n\r\n 1. Jupyter Notebook 44.5%\r\n 2. Python 38.1%\r\n 3. HTML 10.4%\r\n 4. JavaScript 7.0%\r\n\r\nJupyter Notebook Python HTML JavaScript Clone or downloadCLONE WITH HTTPS\r\nUse Git or checkout with SVN using the web URL.\r\n\r\nDownload ZIP Find file Branch: master Switch branches/tags * Branches\r\n * Tags\r\n\r\ndialog master Nothing to show Nothing to show New pull request Latest commit 77c16b6 Aug 18, 2016 vabarbosa add class to pixiedust dialog buttons Permalink Failed to load latest commit information. notebook Updated Bar Chart dialog options Aug 16, 2016 pixiedust add class to pixiedust dialog buttons Aug 18, 2016 .gitignore Updated Bar Chart dialog options Aug 16, 2016 LICENSE Initial commit Jul 1, 2016 MANIFEST.in fixed setup.py to include static templates Jul 18, 2016 README.md First draft Jul 14, 2016 setup.cfg Moved pixiedust to its own repo Jul 1, 2016 setup.py Complete visualization of pandas dataframes as tables Aug 5, 2016README.MD\r\nPIXIEDUST\r\nPixiedust is an open source Python helper library that works as an add-on to\r\nJupyter notebooks to improve the user experience of working with data. It also\r\nprovides extra capabilities that fill a gap when the notebook is hosted on the\r\ncloud and the user has no access to configuration files.\r\n\r\nIts current capabilities include:\r\n\r\n * packageManager lets you install spark packages inside a python notebook. This is something\r\n   that you can't do today on hosted Jupyter notebooks, which prevents\r\n   developers from using a large number of spark package add-ons. The following\r\n   code installs the GraphFrames spark package into your IPython notebook\r\n   \r\n   from pixiedust.packageManager import PackageManager\r\n   pkg=PackageManager()\r\n   pkg.installPackage(\"graphframes:graphframes:0\")\r\n   \r\n   \r\n   \r\n * visualizations. One single API called display lets you visualize your spark object in different ways: table, charts, maps,\r\n   etc.... This module is designed to be extensible, providing an API that lets\r\n   anyone easily contribute a new visualization plugin.\r\n   \r\n   This sample visualization plugin uses d3 to show the different flight routes\r\n   for each airport:\r\n   \r\n   \r\n   \r\n   \r\n * service integration. Stash data into a variety of back-end data sources, like Cloudant, dashDB,\r\n   GraphDB, etc...\r\n   \r\n   \r\n   \r\n   \r\n\r\nNote: Pixiedust currently works only on a Python Notebook hosted on IBM Bluemix.\r\n\r\n * Contact GitHub\r\n * API\r\n * Training\r\n * Shop\r\n * Blog\r\n * About\r\n\r\n * © 2016 GitHub , Inc.\r\n * Terms\r\n * Privacy\r\n * Security\r\n * Status\r\n * Help\r\n\r\nYou can't perform that action at this time. You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session.","url":"https://github.com/ibm-cds-labs/pixiedust","created_at":"2016-08-18 19:50:10 +00:00","updated_at":"2016-08-18 19:52:25 +00:00","imageurl":"https://avatars0.githubusercontent.com/u/12701847?v=3&s=400","status":"Live","languages":["JavaScript","Python"],"technologies":["Bluemix","Cloudant","dashDB","Jupyter","Spark"],"topic":["Notebook","Search"],"featured":"true","demourl":"","githuburl":"","videourl":"","documentationurl":"","author":"","otherurl":"","type":"Project","namespace":["Cloud Data Services"],"related_ids":[]}},
{"id":"f4f3b8051de4622222e621256a15b067a0e091b0","key":"f4f3b8051de4622222e621256a15b067a0e091b0","value":1,"doc":{"_id":"f4f3b8051de4622222e621256a15b067a0e091b0","_rev":"2-185c60132fa3bd29bca61f2f3aa07b2c","name":"bluemix-helper-sso","full_name":"ibm-cds-labs/bluemix-helper-sso","description":"Bluemix Helper for adding support for Single Sign On service to your application","body":"bluemix-helper-sso is a Node.js module library that makes it easy to add authentication to your IBM Bluemix application using Bluemix's Single Sign-On service. You can find more information on the SSO Service here.  Note: Before using this library, please make sure that your application is written in Node.js and is using the Express.js and Passport.js frameworks.","url":"https://github.com/ibm-cds-labs/bluemix-helper-sso","created_at":"2015-11-19 15:19:26 +00:00","updated_at":"2015-11-19 15:19:26 +00:00","imageurl":"https://avatars0.githubusercontent.com/u/12701847?v=3&s=400","status":"Live","languages":["JavaScript"],"technologies":["Bluemix"],"topic":[],"featured":"false","demourl":"","githuburl":"https://github.com/ibm-cds-labs/bluemix-helper-sso","videourl":"","documentationurl":"","author":"","otherurl":"","level":"Intermediate","type":"Article","namespace":["Cloud Data Services"],"related_ids":[]}},
{"id":"f53b5ee5af822721a625c5839b7dc59bd8dc3133","key":"f53b5ee5af822721a625c5839b7dc59bd8dc3133","value":1,"doc":{"_id":"f53b5ee5af822721a625c5839b7dc59bd8dc3133","_rev":"4-30353aa28880ed0bbbeb141bed7643f4","name":"nodejs-cloudant","full_name":"Cloudant Node.js client library","description":"","body":"The best way to use the Cloudant client is to begin with your own Node.js project, and define this work as your dependency. In other words, put me in your package.json dependencies. The npm tool can do this for you.","url":"https://github.com/cloudant/nodejs-cloudant","created_at":"2016-05-02 15:40:35 +00:00","updated_at":"","imageurl":"","status":"Live","languages":["JavaScript","Node.js","HTTP API"],"technologies":["Cloudant"],"topic":["NoSQL"],"featured":"false","demourl":"","githuburl":"https://github.com/cloudant/nodejs-cloudant","videourl":"","documentationurl":"","author":"","otherurl":"","level":"Intermediate","type":"Article","namespace":["Cloud Data Services"],"related_ids":[]}}
]}
